{"componentChunkName":"component---src-templates-page-js","path":"/cooking-game","result":{"data":{"markdownRemark":{"frontmatter":{"title":"Cooking Mama Inspired Arduino controllers","date":"Fall 2018","path":"/cooking-game","author":null,"excerpt":"Unity and Arduino version of popular game Cooking Mama. Made felt fabric controllers shaped like food and put sensors in them. Tweet received over half a million views on Twitter.","tags":["Unity","Physical computing","Arduino","Soft fabrication"],"coverImage":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIDBP/EABYBAQEBAAAAAAAAAAAAAAAAAAECA//aAAwDAQACEAMQAAABsuyJSmwc/wD/xAAaEAADAAMBAAAAAAAAAAAAAAABAgMAEhMx/9oACAEBAAEFAmrsWo0z0jmoCL6yjP/EABYRAQEBAAAAAAAAAAAAAAAAAAEAEf/aAAgBAwEBPwFNLL//xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAgEBPwFX/8QAHBAAAwABBQAAAAAAAAAAAAAAAAERAhIhMTJx/9oACAEBAAY/AtGN9E93idaOIhwf/8QAGhABAAMAAwAAAAAAAAAAAAAAAQARIUFRsf/aAAgBAQABPyE3oJzzZUzxQUF026ikATqaS0lkKUE//9oADAMBAAIAAwAAABA3H//EABgRAAMBAQAAAAAAAAAAAAAAAAABEUFR/9oACAEDAQE/EEsmE9P/xAAWEQEBAQAAAAAAAAAAAAAAAAABABH/2gAIAQIBAT8QFLV//8QAHRABAAMBAAIDAAAAAAAAAAAAAQARITFBYYGRwf/aAAgBAQABPxAKeRg9Ct0ibbOqUqqgrPmJURsKffI0JCkU8nnFxHR1PyDEdAA4bP/Z","aspectRatio":1.7699115044247788,"src":"/static/77e34cb29cea8b24b0691eb82d0b74a6/14b42/cooking_mama.jpg","srcSet":"/static/77e34cb29cea8b24b0691eb82d0b74a6/f836f/cooking_mama.jpg 200w,\n/static/77e34cb29cea8b24b0691eb82d0b74a6/2244e/cooking_mama.jpg 400w,\n/static/77e34cb29cea8b24b0691eb82d0b74a6/14b42/cooking_mama.jpg 800w,\n/static/77e34cb29cea8b24b0691eb82d0b74a6/a7715/cooking_mama.jpg 1000w","sizes":"(max-width: 800px) 100vw, 800px"}}},"coverVideo":{"publicURL":"/static/d116b554ddbbac6e72b4387097faca9b/cooking_mama.mp4"},"links":"on Twitter,https://twitter.com/crabbage_/status/1072711212016828416"},"id":"385ae959-16b7-52ff-aa9f-8d3c6622fb96","html":"<h1>About</h1>\n<p class=\"para\">A Unity and Arduino version of popular game Cooking Mama! I made two felt fabric controllers (one spam, one steak) shaped like food and put sensors in them.\nWhen I first learned how to use an Arduino, one of my first instincts was to connect it with Unity. At first, I had trouble coming up with an idea for a unity and arduino experience that would leverage the advantages of both. Ultimately, I was inspired by Cooking Mama, a game that I had loved in my childhood. I was excited by the idea of enhancing the game experience with a physical controller. How will a felt knife and a felt steak compare to a Nintendo stylus? Will it make it more fun? Will it be the same?</p>\n<p class=\"para\">A demo vieo of this project was popular on Twitter and recieved over half a million views. <a href=\"https://twitter.com/crabbage_/status/1072711212016828416\">See the original tweet here.</a></p>\n<p class=\"para\">Thank you to Sidney Church for helping me connect the Arduino to unity and for all of the Arduino help!</p>\n<p class=\"para\"><img src=\"../images/cooking-mama/meat-salad.gif\" alt=\"example gif of me using the cooking mama felt controller. I am chopping a felt steak, which triggers changes in the game running on the laptop\"></p>\n<p class=\"para\"><em>gif of me using the cooking mama felt controller</em></p>\n<div class=\"br\"></div>\n<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/a2O5I6Tr3ms\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</br>\n<h1>Documentation pictures &#x26; Code</h1>\n<p class=\"para\">The look of the felt fabric food controllers was inspired by Lucy Sparrow's Sparrow Mart, a supermarket made up of food made from felt.\nYou can find the code <a href=\"https://github.com/khanniie/unity-arduino-cooking-mama\">here</a>.\nThe steak controller contains six buttons attached to a breadboard. On top of the buttons, I laid flat acrylic boards that I cut into sections so that the buttons could have a greater range of influence. The spam contains a photocell that can tell when you remove the meat, and the bowl also contains a photocell to detect when the meat is placed inside.\nFor the unity part, I am sending the information from the Arduino to serial port, which unity then reads from.\n<img src=\"../images/cooking-mama/meat-salad-diagram.jpg\" alt=\"diagram of how it works\">\n<em>diagram of how it works</em> </p>\n<p class=\"para\"><img src=\"../images/cooking-mama/meat-salad-documentation.jpg\" alt=\"images of the felt controller in progress\">\n<em>left: the felt steak and fabric parts, right: developing with arduino</em></p>","excerpt":"About A Unity and Arduino version of popular game Cooking Mama! I made two felt fabric controllers (one spam, one steak) shaped like food…"}},"pageContext":{"type":"posts","next":{"id":"c1f1e56f-af6a-50bf-8fe4-872205c348c2","children":[],"parent":"07e3217e-6654-5ffa-8ef3-46a2d2f2a6c4","internal":{"content":"\n# Concept\n\nAs a research assistant in Oh!Lab at Carnegie Mellon, I collaborated with Joseph Seering and Michal Luria to design and program a \"Baby\" chatbot that was designed to interact with a community and grow up over time. Professors Jessica Hammer and Geoff Kaufmann advised on the project and final paper. \n\nIn this project, I designed the chatbot concept and interactions and was the sole programmer in charge of implementation as well. After deploying the study for two weeks, I handled the data analysis afterwards.\n\n<div class=\"fill-row\">\n    <div class=\"flex-item-start\"><img src=\"../images/babybot/bacteria-baby.gif\"/></div>\n    <div class=\"flex-item\"><img src=\"../images/babybot/toddler.gif\"/></div>\n    <div class=\"flex-item\"><img src=\"../images/babybot/teenager-bot.gif\"/></div>\n</div>\n\nOur work builds on [a previous paper published by Joseph, Michal, Geoff Kaufman and Jessica Hammer](https://dl.acm.org/doi/10.1145/3290605.3300680). That paper notes that many current chatbots are designed for one-on-one interactions and argues that:  \n> \"chatbots' social roles and conversational capabilities beyond dyadic interactions have been underexplored, and that expansion into this design space could support richer social interactions in online communities and help address the longstanding challenges of maintaining, moderating, and growing these communities.\"\n\n# Process\n\n## Initial mockups\nFocusing in on the \"dependent\" chatbot suggested by the above paper, I designed many different chatbot concepts, iterated on these concepts and narrowed in onto one type of bot. \n<div id=\"illustrations\">\n    <img src=\"../images/babybot/babybot_initial_bot1.jpeg\" alt=\"concept of a chatbot where a chatbot is an adventurer\"/>\n    <img src=\"../images/babybot/babybot_initial_bot2.jpeg\" alt=\"concept of a chatbot where a chatbot communicates through visual motifs\"/>\n    <img src=\"../images/babybot/babybot_initial_bot3.jpeg\" alt=\"concept of a chatbot where a chatbot changes text over time\"/>\n    <img src=\"../images/babybot/babybot_initial_bot4.jpeg\" alt=\"concept of a chatbot where a chatbot is a mama's boy\"/>\n    <img src=\"../images/babybot/babybot_initial_bot5.png\" alt=\"concept of a chatbot where a chatbot is based on astrology\"/>\n</div>\n\n<div class=\"br\"></div>\n\n## Second iteration of refined mockups & user journey\n<div class=\"fill-row\">\n    <div class=\"flex-item-start\"><img src=\"../images/babybot/advbot-card.jpg\"/></div>\n    <div class=\"flex-item\"><img class=\"flex-item\" src=\"../images/babybot/avdbot-journey.jpg\"/></div>\n</div>\n<div class=\"fill-row\">\n    <div class=\"flex-item-start\"><img src=\"../images/babybot/love-card.jpg\"/></div>\n    <div class=\"flex-item\"><img src=\"../images/babybot/love-journey.jpg\"/></div>\n</div>\n<div class=\"fill-row\">\n    <div class=\"flex-item-start\"><img src=\"../images/babybot/vbot-card.jpg\"/></div>\n    <div class=\"flex-item\"><img src=\"../images/babybot/visual-bot.jpg\"/></div>\n</div>\n\n*above: process illustrations of initial concepts*\n\n<div class=\"br\"></div>\n\n## Flow diagrams \nNext, I took the final concept of an adventuring chatbot to flesh out the possible interactions using this flow diagram.\n![flow diagram](../images/babybot/new-flow.jpg)\n\n<div class=\"br\"></div>\n\n## Development\nOnce we had designed all of the features of Babybot, I then programmed the bot. The chatbot used in this study was developed using Javascript and run locally using Node.js. Package management was handled through npm. We are using several javascript libraries for Twitch relaying, data saving and language generation; notably, we are using tmi.js (v1.4.2) to access Twitch’s Internet Relay Chat, and Rita.js (v1.3.89) to perform natural language processing on our text. \n\n![implementation](../images/babybot/babybot_flow.png)\n\n# For more information about the implementation, study and final insights, please see our paper.\n\n# [Link to paper](https://dl.acm.org/doi/abs/10.1145/3313831.3376708)\n\n## Abstract\n>\"While the majority of research in chatbot design has focused on creating chatbots that engage with users one-on-one, less work has focused on the design of conversational agents for online communities. In this paper we present results from a three week test of a social chatbot in an established online community. During this study, the chatbot \"grew up\" from \"birth\" through its teenage years, engaging with community members and \"learning\" vocabulary from their conversations. We discuss the design of this chatbot, how users' interactions with it evolved over the course of the study, and how it impacted the community as a whole. We discuss how we addressed challenges in developing a chatbot whose vocabulary could be shaped by users, and conclude with implications for the role of machine learning in social interactions in online communities and potential future directions for design of community-based chatbots.\"\n","type":"MarkdownRemark","contentDigest":"c4cb6d4276bec8e96eb629fcf6464cda","counter":179,"owner":"gatsby-transformer-remark"},"frontmatter":{"title":"Babybot","path":"/babybot","date":"Spring 2019 - Fall 2019","coverImage":"../images/babybot.jpg","coverVideo":"../assets/babybot.mp4","tags":["Twitch API","Node.js","UX Research","Chatbots"],"excerpt":"A Twitch chatbot built to bring an online community together. Our paper, It Takes a Village: Integrating an Adaptive Chatbot into an Online Gaming Community, was accepted into CHI 2020. ","links":"Link to paper,https://dl.acm.org/doi/abs/10.1145/3313831.3376708","readMoreButton":"Learn more","order":12,"shortTitle":"Babybot"},"excerpt":"","rawMarkdownBody":"\n# Concept\n\nAs a research assistant in Oh!Lab at Carnegie Mellon, I collaborated with Joseph Seering and Michal Luria to design and program a \"Baby\" chatbot that was designed to interact with a community and grow up over time. Professors Jessica Hammer and Geoff Kaufmann advised on the project and final paper. \n\nIn this project, I designed the chatbot concept and interactions and was the sole programmer in charge of implementation as well. After deploying the study for two weeks, I handled the data analysis afterwards.\n\n<div class=\"fill-row\">\n    <div class=\"flex-item-start\"><img src=\"../images/babybot/bacteria-baby.gif\"/></div>\n    <div class=\"flex-item\"><img src=\"../images/babybot/toddler.gif\"/></div>\n    <div class=\"flex-item\"><img src=\"../images/babybot/teenager-bot.gif\"/></div>\n</div>\n\nOur work builds on [a previous paper published by Joseph, Michal, Geoff Kaufman and Jessica Hammer](https://dl.acm.org/doi/10.1145/3290605.3300680). That paper notes that many current chatbots are designed for one-on-one interactions and argues that:  \n> \"chatbots' social roles and conversational capabilities beyond dyadic interactions have been underexplored, and that expansion into this design space could support richer social interactions in online communities and help address the longstanding challenges of maintaining, moderating, and growing these communities.\"\n\n# Process\n\n## Initial mockups\nFocusing in on the \"dependent\" chatbot suggested by the above paper, I designed many different chatbot concepts, iterated on these concepts and narrowed in onto one type of bot. \n<div id=\"illustrations\">\n    <img src=\"../images/babybot/babybot_initial_bot1.jpeg\" alt=\"concept of a chatbot where a chatbot is an adventurer\"/>\n    <img src=\"../images/babybot/babybot_initial_bot2.jpeg\" alt=\"concept of a chatbot where a chatbot communicates through visual motifs\"/>\n    <img src=\"../images/babybot/babybot_initial_bot3.jpeg\" alt=\"concept of a chatbot where a chatbot changes text over time\"/>\n    <img src=\"../images/babybot/babybot_initial_bot4.jpeg\" alt=\"concept of a chatbot where a chatbot is a mama's boy\"/>\n    <img src=\"../images/babybot/babybot_initial_bot5.png\" alt=\"concept of a chatbot where a chatbot is based on astrology\"/>\n</div>\n\n<div class=\"br\"></div>\n\n## Second iteration of refined mockups & user journey\n<div class=\"fill-row\">\n    <div class=\"flex-item-start\"><img src=\"../images/babybot/advbot-card.jpg\"/></div>\n    <div class=\"flex-item\"><img class=\"flex-item\" src=\"../images/babybot/avdbot-journey.jpg\"/></div>\n</div>\n<div class=\"fill-row\">\n    <div class=\"flex-item-start\"><img src=\"../images/babybot/love-card.jpg\"/></div>\n    <div class=\"flex-item\"><img src=\"../images/babybot/love-journey.jpg\"/></div>\n</div>\n<div class=\"fill-row\">\n    <div class=\"flex-item-start\"><img src=\"../images/babybot/vbot-card.jpg\"/></div>\n    <div class=\"flex-item\"><img src=\"../images/babybot/visual-bot.jpg\"/></div>\n</div>\n\n*above: process illustrations of initial concepts*\n\n<div class=\"br\"></div>\n\n## Flow diagrams \nNext, I took the final concept of an adventuring chatbot to flesh out the possible interactions using this flow diagram.\n![flow diagram](../images/babybot/new-flow.jpg)\n\n<div class=\"br\"></div>\n\n## Development\nOnce we had designed all of the features of Babybot, I then programmed the bot. The chatbot used in this study was developed using Javascript and run locally using Node.js. Package management was handled through npm. We are using several javascript libraries for Twitch relaying, data saving and language generation; notably, we are using tmi.js (v1.4.2) to access Twitch’s Internet Relay Chat, and Rita.js (v1.3.89) to perform natural language processing on our text. \n\n![implementation](../images/babybot/babybot_flow.png)\n\n# For more information about the implementation, study and final insights, please see our paper.\n\n# [Link to paper](https://dl.acm.org/doi/abs/10.1145/3313831.3376708)\n\n## Abstract\n>\"While the majority of research in chatbot design has focused on creating chatbots that engage with users one-on-one, less work has focused on the design of conversational agents for online communities. In this paper we present results from a three week test of a social chatbot in an established online community. During this study, the chatbot \"grew up\" from \"birth\" through its teenage years, engaging with community members and \"learning\" vocabulary from their conversations. We discuss the design of this chatbot, how users' interactions with it evolved over the course of the study, and how it impacted the community as a whole. We discuss how we addressed challenges in developing a chatbot whose vocabulary could be shaped by users, and conclude with implications for the role of machine learning in social interactions in online communities and potential future directions for design of community-based chatbots.\"\n","fileAbsolutePath":"/Users/crabbage/Documents/newwebdev/src/posts/babybot.md","__gatsby_resolved":{"frontmatter":{"path":"/babybot"}}},"previous":{"id":"3d8b1d1f-bc63-52ac-9b1d-6d5495cef785","children":[],"parent":"308b7361-1bfb-5635-8680-19f15bde6f59","internal":{"content":"\n# Project\n\nIn Summer and Fall 2020, I was a UX Engineering intern on Google's AR team (formerly known as Daydream). Although the nature of the project is still confidential, I can still talk generally about some of the skills that I used and the lessons that I learned. If you'd like to learn more, please reach out :-). If you're a Google employee, contact me.\n\nTowards the end of my summer internship, my team extended my internship through a small program at Google that allows interns to continue working part-time while in university. So during the Fall semester of my senior year, I worked part-time (20% for a month, and then 50% for two months). \n\nThis was my first time working in a product-focused team. As part of the UX team, I worked closely with other UXers, but also interacted with PMs and software engineers to help investigate UX and research questions. \n\n# Technologies / skills\n1. Android app development with Android Studio\n2. Android/iOS app development with Unity and AR Foundation\n3. Google Cloud Vision API integration\n4. Web development \n5. 3D modeling with Autodesk Maya\n6. Demo and concept video editing with Adobe suite\n7. Illustration under the direction of a creative director for internal projects\n8. Human-centered design thinking\n9. Prototyping and iteration\n10. System and Input UX design\n11. OpenCV\n12. Stats and research\n\n![work from home](../images/google-ar/WFH.jpg)\n<em>My desk while I worked from home!</em>\n\nThank you to my intern host Shiblee, who taught me so much about hardware UX, augmented reality, and more. He was an amazing manager! Also thank you to my co-host Wendy, an incredible designer and mentor.","type":"MarkdownRemark","contentDigest":"e09a8f96c54f91902412708be5e8ff27","counter":170,"owner":"gatsby-transformer-remark"},"frontmatter":{"title":"Google AR Internship","date":"Summer/Fall 2020 (@WFH)","path":"/google-ar","author":"Lorem Ipsum","coverImage":"../images/ar-thumb.jpg","coverVideo":"../assets/ar-thumbnail.mp4","links":"","tags":["Hardware UX","Android","Unity","AR","OpenCV"],"excerpt":"Developed Android apps to research cutting-edge user experiences within Google's Devices product area.","readMoreButton":"Learn more","shortTitle":"Google AR","order":10},"excerpt":"","rawMarkdownBody":"\n# Project\n\nIn Summer and Fall 2020, I was a UX Engineering intern on Google's AR team (formerly known as Daydream). Although the nature of the project is still confidential, I can still talk generally about some of the skills that I used and the lessons that I learned. If you'd like to learn more, please reach out :-). If you're a Google employee, contact me.\n\nTowards the end of my summer internship, my team extended my internship through a small program at Google that allows interns to continue working part-time while in university. So during the Fall semester of my senior year, I worked part-time (20% for a month, and then 50% for two months). \n\nThis was my first time working in a product-focused team. As part of the UX team, I worked closely with other UXers, but also interacted with PMs and software engineers to help investigate UX and research questions. \n\n# Technologies / skills\n1. Android app development with Android Studio\n2. Android/iOS app development with Unity and AR Foundation\n3. Google Cloud Vision API integration\n4. Web development \n5. 3D modeling with Autodesk Maya\n6. Demo and concept video editing with Adobe suite\n7. Illustration under the direction of a creative director for internal projects\n8. Human-centered design thinking\n9. Prototyping and iteration\n10. System and Input UX design\n11. OpenCV\n12. Stats and research\n\n![work from home](../images/google-ar/WFH.jpg)\n<em>My desk while I worked from home!</em>\n\nThank you to my intern host Shiblee, who taught me so much about hardware UX, augmented reality, and more. He was an amazing manager! Also thank you to my co-host Wendy, an incredible designer and mentor.","fileAbsolutePath":"/Users/crabbage/Documents/newwebdev/src/posts/google_ar.md","__gatsby_resolved":{"frontmatter":{"path":"/google-ar"}}}}},"staticQueryHashes":["236058478","3128451518"]}